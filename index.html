---
layout: home
---

<div class="sechighlight">
<div class="container sec">
	<h2>Description</h2>
	<div id="coursedesc">
	<p>This course studies learning visual representations for common computer vision tasks including matching, retrieval, classification, and object detection. Related problems are discussed including indexing, nearest neighbor search, clustering, and dimensionality reduction. The course discusses well-known methods from low-level description to intermediate representation, and their dependence on the end task. It then studies a data-driven approach where the entire pipeline is optimized jointly in a supervised fashion, according to a task-dependent objective. Deep learning models are studied in detail and interpreted in connection to conventional models. The focus of the course is on recent, state of the art methods and large scale applications.</p>
	<p>The course is part of master program <a href="http://master.irisa.fr/">Research in Computer Science (SIF)</a> of <a href="https://www.univ-rennes1.fr/">University of Rennes 1</a>.</p>
	<p>The following refers to the first iteration of the course in <b>Nov. 2017 - Jan. 2018</b>.</p>
	</div>
</div>
</div>


<div class="container sec">
  <div class="row">
    <div class="col-md-3">
      <h2>Instructor</h2>
      <a href="http://image.ntua.gr/iva/iavr/">Yannis Avrithis</a>
    </div>
    <div class="col-md-3">
      <h2>Discussions</h2>
      <a href="https://piazza.com/inria.fr/fall2017/dlv">Piazza</a>
    </div>
    <div class="col-md-3">
      <h2>Class</h2>
      Monday and Wednesday <br>
      16:15 - 18:15 <br>
    </div>
    <div class="col-md-3">
      <h2>Evaluation</h2>
      Oral presentations: 50%<br>
      Written exam: 50%<br>
    </div>
  </div>
  </div>
</div>


<div class="sechighlight">
<div class="container sec">
  <h2>Planning and Syllabus</h2>
</div>
</div>

<div class="container sec">
	<table class="table">
		<tr class="active">
			<th>Event</th><th>Date</th><th>Room</th><th>Description</th>
			<th><a href="#permission">Material<sup>*</sup></a></th>
		</tr>
		<tr>
			<td>Lecture&nbsp;1</td>
			<td>Monday<br>Nov 20</td>
			<td>B02B-E110 (23)</td>
			<td>
				<b>Introduction</b> <br>
				Research field. Neuroscience, computer vision and machine learning background. Modern deep learning. About this course.
			</td>
			<td>
				<a href='slides/intro.pdf'>[slides]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;2</td>
			<td>Wednesday<br>Nov 22</td>
			<td>B12D i-59 (44)</td>
			<td>
				<b>Representation</b> <br>
				Global/local visual descriptors, dense/sparse representation, feature detectors. Encoding/pooling, vocabularies, bag-of-words. Match kernels, embedding, Fisher vectors, VLAD.
			</td>
			<td>
				<a href='slides/repr.pdf'>[slides]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;3</td>
			<td>Monday<br>Nov 27</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Matching</b> <br>
				Spatial matching, geometric models, RANSAC, Hough transform. Pyramid matching, spatial and Hough pyramids. Object detection, subwindow search, Hough model, deformable part model.
			</td>
			<td>
				<a href='slides/match.pdf'>[slides]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;4</td>
			<td>Wednesday<br>Dec 6</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Indexing</b> <br>
				Clustering, dimensionality reduction, density estimation, nearest neighbor search. Tree-based methods, hashing, product quantization. Inverted index and multi-index.
			</td>
			<td>
				<a href='slides/index.pdf'>[slides]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;5</td>
			<td>Monday<br>Dec 11</td>
			<td>B12D i-59 (44)</td>
			<td>
				<b>Learning</b> <br>
				Naive Bayes, nearest neighbor classification. Regression, classification. Logistic regression, support vector machines, neural networks. Activation functions, loss functions, gradient descent.
			</td>
			<td>
				<a href='slides/learn.pdf'>[slides]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;6</td>
			<td>Wednesday<br>Dec 13</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Differentiation</b> <br>
				Computational graphs, back-propagation, automatic differentiation.
			</td>
			<td>
				[slides]
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;7</td>
			<td>Monday<br>Dec 18</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Convolution</b> <br>
				Pooling, strided convolution, dilated convolution. Convolutional networks. Deconvolution, fully convolutional networks.
			</td>
			<td>
				[slides]
			</td>
		</tr>
		<tr class="info">
			<td>Milestone</td>
			<td>Tuesday<br>Dec 19</td>
			<td></td>
			<td>
				<b>Oral presentation</b> <br>
				Selection of papers to present.
			</td>
			<td>
				<a href="oral">[instructions]</a>
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;8</td>
			<td>Wednesday<br>Jan 10</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Optimization</b> <br>
				Parameter initialization, data-dependent initialization, normalization, regularization. Optimization methods, second-order methods, Hessian-free methods.
			</td>
			<td>
				[slides]
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;9</td>
			<td>Monday<br>Jan 15</td>
			<td>B12D i-52 (44)</td>
			<td>
				<b>Detection</b> <br>
				Class-agnostic region proposals, bounding box regression, non-maxima suppression, part-based models, spatial transformers, attention networks.
			</td>
			<td>
				[slides]
			</td>
		</tr>
		<tr>
			<td>Lecture&nbsp;10</td>
			<td>Monday<br>Jan 22</td>
			<td>B12D i-52 (44)</td>
			<td>
				<b>Retrieval</b> <br>
				Siamese, triplet, and batch-wise loss functions. Embedding, pooling, dimensionality reduction and manifold learning. Partial matching, spatial matching, quantization, diffusion.
			</td>
			<td>
				[slides]
			</td>
		</tr>
		<tr class="warning">
			<td>Evaluation&nbsp;1</td>
			<td>Wednesday<br>Jan 24</td>
			<td>B12D i-58 (44)</td>
			<td>
				<b>Written exam</b> <br>
			</td>
			<td>
				<a href=''></a>
			</td>
		</tr>
		<tr class="warning">
			<td>Evaluation&nbsp;2</td>
			<td>Monday<br>Jan 29</td>
			<td>Jersey</td>
			<td>
				<b>Oral presentations</b> <br>08:00 - 12:00 <br>
			</td>
			<td>
				<a href="oral">[instructions]</a>
			</td>
		</tr>
	</table>
	<p><a name="permission">
		<sup>*</sup>Permission is hereby given to download and reproduce the material for non-commercial purposes including education and research, provided the source is acknowledged.
	</a></p>
</div>


<div class="container sec">
	<h2>Prerequisites</h2> <br>
	Basic knowledge of Linear Algebra, Calculus, Probabilities, Machine Learning, Python, C++.
</div>
